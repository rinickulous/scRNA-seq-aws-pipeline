/*
========================================================================================
    AWS Batch Configuration
========================================================================================
*/

process {
    executor = 'awsbatch'
    queue = params.awsqueue
    
    // AWS Batch error retry strategy
    errorStrategy = { task.exitStatus in [143,137,104,134,139,140,1] ? 'retry' : 'finish' }
    maxRetries = 2
    maxErrors = '-1'
}

aws {
    region = params.awsregion
    batch {
        cliPath = params.awscli
        maxParallelTransfers = 10
        maxTransferAttempts = 3
        // CRITICAL: Sanitize job names for AWS Batch
        jobName = { task.name.replaceAll(':', '_').replaceAll('[^a-zA-Z0-9_-]', '_').toLowerCase().take(30) }
    }
}

// Use S3 for work directory
workDir = "s3://scrna-pipeline-nwhite-work/work"

// Docker settings for AWS Batch
docker {
    enabled = true
    temp = 'auto'
}

// Process-specific resource requirements
process {
    withLabel: process_low {
        cpus = 2
        memory = '8.GB'
    }
    
    withLabel: process_medium {
        cpus = 4
        memory = '16.GB'
    }
    
    withLabel: process_high {
        cpus = 8
        memory = '64.GB'
    }
    
    withName: 'CELLRANGER_COUNT' {
        cpus = 8
        memory = '64.GB'
    }
    
    withName: 'SEURAT_ANALYSIS' {
        cpus = 4
        memory = '32.GB'
    }
}
